var searchIndex = JSON.parse('{\
"llamapun":{"doc":"The <code>LLaMaPUn</code> library in RustLanguage and Mathematics …","i":[[0,"util","llamapun","Various useful code snippets",null,null],[0,"data_helpers","llamapun::util","Helpers with transactional logic related to llamapun::data…",null,null],[3,"LexicalOptions","llamapun::util::data_helpers","Options for lexical normalization on an individual word",null,null],[12,"discard_math","","math will be entirely omitted when set",0,null],[12,"discard_punct","","non-alphanumeric characters will be entirely omitted when …",0,null],[12,"discard_case","","all letters will be lowercased when set",0,null],[5,"ams_normalize_word_range","","Normalization of word lexemes created for the \\\"AMS …",null,[[["dnmrange",3],["lexicaloptions",3],["context",3]],[["result",4],["string",3],["box",3]]]],[5,"heading_from_node_aux","","Provides a string for a given heading node, using …",null,[[["tokenizer",3],["ronode",3],["context",3]],[["option",4],["string",3]]]],[5,"normalize_heading_title","","Attempt to recover the \\\"type\\\" of a potentially …",null,[[["str",15]],["string",3]]],[5,"invalid_for_english_latin","","Check if the given DNM contains valid English+Latin …",null,[[["dnm",3]],["bool",15]]],[0,"path_helpers","llamapun::util","Helpers intended mostly for non-Rust use, where rust is …",null,null],[5,"path_to_words","llamapun::util::path_helpers","Given a path to a document, return a word-tokenized …",null,[[["string",3]],["string",3]]],[0,"plot","llamapun::util","Some plotting functionality using gnuplot",null,null],[5,"plot_simple","llamapun::util::plot","A simple plot",null,[[["str",15]]]],[0,"test","llamapun::util","Test utilities for llamapun\'s crate",null,null],[3,"RESOURCE_DOCUMENTS","llamapun::util::test","shorthand global for all usable documents in the …",null,null],[0,"token_model","llamapun::util","A \\\"corpus token model\\\"-generation utilities",null,null],[5,"extract","llamapun::util::token_model","Parallel traversal of latexml-style HTML5 document …",null,[[["bool",15],["string",3]],[["result",4],["hashmap",3],["box",3]]]],[0,"ams","llamapun","Representation, normalization and utilities for working …",null,null],[5,"has_markup","llamapun::ams","Checks a llamapun <code>Document</code> for \'ltx_theorem\' AMS markup",null,[[["document",3]],["bool",15]]],[5,"has_markup_xmldoc","","Checks a libxml document for <code>ltx_theorem</code> AMS markup",null,[[["xmldoc",3]],["bool",15]]],[4,"StructuralEnv","","Semantically fixed structural environments in scientific …",null,null],[13,"Abstract","","",1,null],[13,"Acknowledgement","","",1,null],[13,"Analysis","","",1,null],[13,"Application","","",1,null],[13,"Assumption","","",1,null],[13,"Background","","",1,null],[13,"Case","","",1,null],[13,"Caption","","",1,null],[13,"Claim","","",1,null],[13,"Conclusion","","",1,null],[13,"Condition","","",1,null],[13,"Conjecture","","",1,null],[13,"Contribution","","",1,null],[13,"Corollary","","",1,null],[13,"Data","","",1,null],[13,"Dataset","","",1,null],[13,"Definition","","",1,null],[13,"Demonstration","","",1,null],[13,"Description","","",1,null],[13,"Discussion","","",1,null],[13,"Example","","",1,null],[13,"Experiment","","",1,null],[13,"Fact","","",1,null],[13,"FutureWork","","",1,null],[13,"Implementation","","",1,null],[13,"Introduction","","",1,null],[13,"Lemma","","",1,null],[13,"Methods","","",1,null],[13,"Model","","",1,null],[13,"Motivation","","",1,null],[13,"Notation","","",1,null],[13,"Observation","","",1,null],[13,"Other","","",1,null],[13,"Preliminaries","","",1,null],[13,"Problem","","A task to be solved (sometimes with solution following), …",1,null],[13,"Proof","","",1,null],[13,"Property","","",1,null],[13,"Proposition","","",1,null],[13,"Question","","",1,null],[13,"RelatedWork","","",1,null],[13,"Remark","","",1,null],[13,"Result","","",1,null],[13,"Simulation","","",1,null],[13,"Step","","",1,null],[13,"Summary","","",1,null],[13,"Theorem","","",1,null],[13,"Theory","","",1,null],[4,"AmsEnv","","Author-annotated \\\\newthorem{} environments using the …",null,null],[13,"Acknowledgement","","typically co-author support for a proof/paper (also …",2,null],[13,"Algorithm","","usually defines a computer science algorithm (also …",2,null],[13,"Answer","","To be analyzed (?)",2,null],[13,"Affirmation","","To be analyzed (?)",2,null],[13,"Assumption","","assumption/axiom/assertion/prior -- should they be …",2,null],[13,"Bound","","To be analyzed (?)",2,null],[13,"Caption","","usually an actual Figure or Table captions realized via …",2,null],[13,"Case","","A case in a multi-step proof / description / exposition",2,null],[13,"Claim","","To be analyzed (?)",2,null],[13,"Comment","","To be analyzed (?)",2,null],[13,"Conclusion","","To be analyzed (?)",2,null],[13,"Condition","","Potentially a constraint on a proof",2,null],[13,"Conjecture","","An unproven statement/theorem (includes \\\"conjecture\\\", …",2,null],[13,"Constraint","","To be analyzed (?)",2,null],[13,"Convention","","To be analyzed (?)",2,null],[13,"Corollary","","A direct-to-derive consequence of a prior proposition",2,null],[13,"Criterion","","To be analyzed (?)",2,null],[13,"Definition","","Unlike notations, introduces new conceptual mathematical …",2,null],[13,"Demonstration","","To be analyzed (?)",2,null],[13,"Discussion","","To be analyzed (?)",2,null],[13,"Example","","Demonstration of a definition, notation etc (also …",2,null],[13,"Experiment","","To be analyzed (?)",2,null],[13,"Expansion","","To be analyzed (?)",2,null],[13,"Expectation","","To be analyzed (?)",2,null],[13,"Explanation","","To be analyzed (?)",2,null],[13,"Fact","","To be analyzed (?)",2,null],[13,"Hint","","To be analyzed (?)",2,null],[13,"Issue","","To be analyzed (?)",2,null],[13,"Keywords","","To be analyzed (?)",2,null],[13,"Lemma","","A smaller sub-theorem to a main theorem",2,null],[13,"Notation","","Introduces a new syntactic rule, usually for convenience …",2,null],[13,"Note","","To be analyzed (?)",2,null],[13,"Notice","","To be analyzed (?)",2,null],[13,"Observation","","To be analyzed (?)",2,null],[13,"Paragraph","","A named paragraph, without a clear standalone function",2,null],[13,"Principle","","To be analyzed (?)",2,null],[13,"Problem","","A task to be solved (sometimes with solution following), …",2,null],[13,"Proof","","Proves a prior theorem/lemma",2,null],[13,"Proposition","","A provably true/false statement. Is this a synonym to …",2,null],[13,"Question","","(sometimes) initial goal of inquiry (also \\\"puzzle\\\", …",2,null],[13,"Remark","","A comment that is an aside to the main line of reasoning",2,null],[13,"Result","","Summarizes paper\'s experimental deliverables",2,null],[13,"Rule","","To be analyzed (?)",2,null],[13,"Solution","","To be analyzed (?)",2,null],[13,"Step","","A part of a proof, or demonstration/layout",2,null],[13,"Summary","","To be analyzed (?)",2,null],[13,"Theorem","","A main proposition to be proven in the document",2,null],[13,"Other","","Anything else that was marked up with AMS, but doesn\'t …",2,null],[5,"class_to_env","","Maps a latexml-produced HTML class, such as \\\"ltx_theorem …",null,[[["str",15]],[["option",4],["amsenv",4]]]],[5,"normalize_env","","If known, maps a commonly used AMS environment to a …",null,[[["str",15]],["amsenv",4]]],[0,"data","llamapun","Data structures and Iterators for convenient high-level …",null,null],[3,"Corpus","llamapun::data","An iterable Corpus of HTML5 documents",null,null],[12,"path","","root directory",3,null],[12,"xml_parser","","document XHTML5 parser",3,null],[12,"html_parser","","document HTML5 parser",3,null],[12,"tokenizer","","<code>DNM</code>-aware sentence and word tokenizer",3,null],[12,"senna","","<code>Senna</code> object for shallow language analysis",3,null],[12,"senna_options","","<code>Senna</code> parsing options",3,null],[12,"dnm_parameters","","Default setting for <code>DNM</code> generation",3,null],[12,"extension","","Extension of corpus files (for specially tailored …",3,null],[3,"DocumentIterator","","File-system iterator yielding individual documents",null,null],[12,"corpus","","reference to the parent corpus",4,null],[3,"Document","","One of our math documents.",null,null],[12,"dom","","The DOM of the document",5,null],[12,"path","","The file path of the document",5,null],[12,"corpus","","A reference to the corpus containing this document",5,null],[12,"dnm","","If it exists, the DNM corresponding to this document",5,null],[3,"ParagraphIterator","","An iterator over paragraphs of a <code>Document</code>. Ignores …",null,null],[12,"document","","A reference to the document over which we iterate",6,null],[3,"Paragraph","","A paragraph of a document with a DNM",null,null],[12,"dnm","","The dnm of this paragraph",7,null],[12,"document","","A reference to the document containing this paragraph",7,null],[3,"SentenceIterator","","An iterator over the sentences of a document/paragraph",null,null],[12,"document","","A reference to the document we are working on",8,null],[3,"Sentence","","A sentence in a document",null,null],[12,"range","","The range of the sentence",9,null],[12,"document","","The document containing this sentence",9,null],[12,"senna_sentence","","If it exists, also the senna version of the sentence, …",9,null],[3,"SimpleWordIterator","","An iterator over the words of a sentence, where the words …",null,null],[12,"sentence","","The sentence containing the words",10,null],[3,"SennaWordIterator","","An iterator over the words of a sentence, where the words …",null,null],[12,"sentence","","The sentence we are iterating over",11,null],[3,"Word","","A word with a POS tag",null,null],[12,"range","","The range of the word",12,null],[12,"sentence","","The sentence containing this word",12,null],[12,"pos","","The part-of-speech tag of the word (or POS::NOT_SET)",12,null],[11,"new","","Create a new corpus with the base directory <code>dirpath</code>",3,[[["string",3]]]],[11,"iter","","Get an iterator over the documents",3,[[],["documentiterator",3]]],[11,"load_doc","","Load a specific document in the corpus",3,[[["string",3]],[["xmlparseerror",4],["result",4],["document",3]]]],[11,"new","","Load a new document",5,[[["string",3],["corpus",3]],[["result",4],["xmlparseerror",4]]]],[11,"paragraph_nodes","","Obtain the problem-free logical paragraphs of a libxml …",5,[[["xmldoc",3]],[["vec",3],["ronode",3]]]],[11,"paragraph_iter","","Get an iterator over the paragraphs of the document",5,[[],["paragraphiterator",3]]],[11,"get_math_nodes","","Obtain the MathML  nodes of a libxml <code>Document</code>",5,[[],[["vec",3],["ronode",3]]]],[11,"get_ref_nodes","","Obtain the <span[class=ltx_ref]> nodes of a libxml …",5,[[],[["vec",3],["ronode",3]]]],[11,"sentence_iter","","Get an iterator over the sentences of the document",5,[[],["sentenceiterator",3]]],[11,"iter","","Get an iterator over the sentences in this paragraph",7,[[],["sentenceiterator",3]]],[11,"simple_iter","","Get an iterator over the words (using rudimentary …",9,[[],["simpleworditerator",3]]],[11,"senna_iter","","Get an iterator over the words using Senna",9,[[],["sennaworditerator",3]]],[11,"senna_parse","","Parses the sentence using Senna. The parse options are …",9,[[]]],[0,"dnm","llamapun","The <code>dnm</code> can be used for easier switching between the DOM …",null,null],[0,"node","llamapun::dnm","Node auxiliaries for DNMs",null,null],[5,"lexematize_math","llamapun::dnm::node","Map math nodes to their lexemes",null,[[["ronode",3],["context",3]],["string",3]]],[3,"DNMParameters","llamapun::dnm","Parameters for the DNM generation",null,null],[12,"special_tag_name_options","","How to deal with special tags (e.g. <code><math></code> tags)",13,null],[12,"special_tag_class_options","","How to deal with tags with special class names (e.g. …",13,null],[12,"normalize_white_spaces","","merge sequences of whitespaces into a single \' \'. <em>Doesn\'t …",13,null],[12,"wrap_tokens","","put spaces before and after tokens",13,null],[12,"normalize_unicode","","Replace unicode characters by the ascii code …",13,null],[12,"stem_words_once","","Apply the morpha stemmer once to the text nodes",13,null],[12,"stem_words_full","","Apply the morpha stemmer to the text nodes as often as it …",13,null],[12,"convert_to_lowercase","","Move to lowercase (remark: The stemmer does this …",13,null],[12,"support_back_mapping","","Support back mapping, i.e. mapping plaintext offsets back …",13,null],[3,"RuntimeParseData","","Some temporary data for the parser",null,null],[12,"had_whitespace","","plaintext is currently terminated by some whitespace",14,null],[12,"chars","","plaintext representation as vector of chars (to deal with …",14,null],[4,"SpecialTagsOption","","Specifies how to deal with a certain tag",null,null],[13,"Enter","","Recurse into tag (default behaviour)",15,null],[13,"Normalize","","Normalize tag, replacing it by some token",15,null],[13,"FunctionNormalize","","Normalize tag, obtain replacement string by function call",15,null],[13,"Skip","","Skip tag",15,null],[3,"DNMRange","","Very often we\'ll talk about substrings of the plaintext - …",null,null],[12,"start","","Offset of the beginning of the range",16,null],[12,"end","","Offset of the end of the range",16,null],[12,"dnm","","DNM containing this range",16,null],[3,"DNM","","The <code>DNM</code> is essentially a wrapper around the plain text …",null,null],[12,"plaintext","","The plaintext",17,null],[12,"byte_offsets","","As the plaintext is UTF-8: the byte offsets of the …",17,null],[12,"parameters","","The options for generation",17,null],[12,"root_node","","The root node of the underlying xml tree",17,null],[12,"node_map","","Maps nodes to plaintext offsets",17,null],[12,"runtime","","A runtime object used for holding auxiliary state",17,null],[12,"back_map","","maps an offset to the corresponding node, and the offset …",17,null],[11,"new","","Creates a <code>DNM</code> for <code>root</code>",17,[[["ronode",3],["dnmparameters",3]],["dnm",3]]],[11,"from_str","","Use the DNM abstraction over a plaintext utterance, …",17,[[["option",4],["dnmparameters",3],["str",15]],[["box",3],["result",4]]]],[11,"from_ams_paragraph_str","","Rebuild a llamapun-generated tokenized plaintext into a …",17,[[["option",4],["dnmparameters",3],["str",15]],[["box",3],["result",4]]]],[11,"get_range_of_node","","Get the plaintext range of a node",17,[[["ronode",3]],[["result",4],["box",3],["dnmrange",3]]]],[11,"get_range","","Get the range representing the full DNM",17,[[],[["result",4],["box",3],["dnmrange",3]]]],[11,"get_plaintext","","Get the underlying text for this DNM",17,[[],["str",15]]],[0,"ngrams","llamapun","A small ngram library ngrams are sequences of n …",null,null],[3,"Dictionary","llamapun::ngrams","Records single words, in order of appearance",null,null],[12,"map","","hashmap for the records",18,null],[11,"new","","create a new dictionary",18,[[]]],[11,"insert","","insert a new word into the dictionary (if it hasn\'t been …",18,[[["string",3]]]],[11,"sorted","","get the entries of the dictionary sorted by occurence",18,[[],["vec",3]]],[11,"count","","get the number of entries in the dictionary",18,[[],["usize",15]]],[3,"Ngrams","","Ngrams are dictionaries with",null,null],[12,"anchor","","anchor word that must be present in all ngram contexts …",19,null],[12,"window_size","","if an anchor word is given, word window size, applied to …",19,null],[12,"n","","n-grams for a sequence of n words",19,null],[12,"counts","","statistics hashmap for the occurence counts",19,null],[11,"get","","Get the word count",19,[[["str",15]],["usize",15]]],[11,"insert","","count a newly seen ngram phrase",19,[[["string",3]]]],[11,"sorted","","obtain the ngram report, sorted by descending frequency",19,[[],["vec",3]]],[11,"distinct_count","","get the number of distinct ngrams recorded",19,[[],["usize",15]]],[11,"add_content","","add content for ngram analysis, typically a paragraph or …",19,[[["str",15]]]],[11,"add_anchored_content","","In essence, for a given window size W, a word at index i …",19,[[["str",15]]]],[11,"record_words","","Take an arbitrarily long vector of words, and record all …",19,[[["vec",3],["str",15]]]],[0,"parallel_data","llamapun","Data structures and Iterators for rayon-enabled parallel …",null,null],[0,"corpus","llamapun::parallel_data","container and API for a Corpus capable of parallel walks …",null,null],[3,"Corpus","llamapun::parallel_data::corpus","A parallel iterable Corpus of HTML5 documents",null,null],[12,"path","","root directory",20,null],[12,"xml_parser","","document XHTML5 parser",20,null],[12,"html_parser","","document HTML5 parser",20,null],[12,"tokenizer","","<code>DNM</code>-aware sentence and word tokenizer",20,null],[12,"dnm_parameters","","Default setting for <code>DNM</code> generation",20,null],[12,"extension","","Extension of corpus files (for specially tailored …",20,null],[11,"new","","Create a new parallel-processing corpus with the base …",20,[[["string",3]]]],[11,"catalog_with_parallel_walk","","Get a parallel iterator over the documents",20,[[],[["u64",15],["hashmap",3],["string",3]]]],[0,"document","llamapun::parallel_data","container and API for a Document yielded during a …",null,null],[3,"Document","llamapun::parallel_data::document","One of our math documents, thread-friendly",null,null],[12,"dom","","The DOM of the document",21,null],[12,"path","","The file path of the document",21,null],[12,"corpus","","A reference to the corpus containing this document",21,null],[12,"dnm","","If it exists, the DNM corresponding to this document",21,null],[11,"new","","Load a new document",21,[[["string",3],["corpus",3]],[["result",4],["xmlparseerror",4]]]],[11,"get_heading_nodes","","Obtain the problem-free logical headings of a libxml …",21,[[],[["vec",3],["ronode",3]]]],[11,"heading_iter","","Get an iterator over the headings of the document",21,[[],["ronodeiterator",3]]],[11,"get_paragraph_nodes","","Obtain the problem-free logical paragraphs of a libxml …",21,[[],[["vec",3],["ronode",3]]]],[11,"paragraph_iter","","Get an iterator over the paragraphs of the document",21,[[],["ronodeiterator",3]]],[11,"extended_paragraph_iter","","Get an iterator over textual paragraphs of the document, …",21,[[],["ronodeiterator",3]]],[11,"get_math_nodes","","Obtain the MathML  nodes of a libxml <code>Document</code>",21,[[],[["vec",3],["ronode",3]]]],[11,"get_ref_nodes","","Obtain the <span[class=ltx_ref]> nodes of a libxml …",21,[[],[["vec",3],["ronode",3]]]],[11,"sentence_iter","","Get an iterator over the sentences of the document",21,[[],["dnmrangeiterator",3]]],[11,"get_xpath_nodes","","Obtain the nodes associated with the xpath evaluation …",21,[[["str",15]],[["vec",3],["ronode",3]]]],[11,"get_xpath_node","","Obtain the first node associated with the xpath …",21,[[["str",15]],[["ronode",3],["option",4]]]],[11,"xpath_selector_iter","","Get an iterator over a custom xpath selector over the …",21,[[["str",15]],["ronodeiterator",3]]],[11,"filter_iter","","Get an iterator using a custom closure predicate filter …",21,[[["fn",8]],["ronodeiterator",3]]],[3,"ItemDNM","llamapun::parallel_data","A DNM with associated document parent (e.g. for …",null,null],[12,"dnm","","The payload of the item",22,null],[12,"document","","A reference to the parent document",22,null],[3,"ItemDNMRange","","A DNMRange with associated document",null,null],[12,"range","","The range of the sentence",23,null],[12,"document","","The document containing this sentence",23,null],[3,"RoNodeIterator","","Generic iterater over read-only xml nodes. It is the …",null,null],[12,"document","","A reference to the owner document",24,null],[3,"DNMRangeIterator","","A generic iterator over DNMRanges with their associated …",null,null],[12,"document","","A reference to the document we are working on",25,null],[8,"XPathFilteredIterator","","An iterator adaptor for filtered selections over a …",null,null],[10,"to_sentences","","the sentences for the resulting selection",26,[[],[["vec",3],["dnmrange",3]]]],[10,"get_document","","the owner document being selected over",26,[[],["document",3]]],[11,"iter","","Get an iterator over the sentences in this paragraph",26,[[],["dnmrangeiterator",3]]],[11,"word_iter","","Get an iterator over the words (using rudimentary …",23,[[],["dnmrangeiterator",3]]],[11,"word_and_punct_iter","","Get an iterator over the words and punctuation (using …",23,[[],["dnmrangeiterator",3]]],[11,"word_iter","","Get an iterator over the words (using rudimentary …",22,[[],["dnmrangeiterator",3]]],[11,"word_and_punct_iter","","Get an iterator over the words and punctuation (using …",22,[[],["dnmrangeiterator",3]]],[0,"patterns","llamapun","A module for pattern matching in mathematical documents",null,null],[5,"match_sentence","llamapun::patterns","returns the matches in a sentence",null,[[["str",15],["dnmrange",3],["sentence",3],["patternfile",3]],[["string",3],["result",4],["vec",3]]]],[3,"Match","","A <code>Match</code>. Note that matches are represented in a tree …",null,null],[12,"marker","","The marker associated with this match",27,null],[12,"sub_matches","","The sub-matches",27,null],[4,"MarkerEnum","","Any marked result",null,null],[13,"Text","","a marked text range",28,null],[13,"Math","","a marked math node",28,null],[3,"MathMarker","","A marked math node",null,null],[12,"node","","the marked math node",29,null],[12,"marker","","the marker",29,null],[3,"PatternFile","","Contains rules loaded from a pattern file",null,null],[12,"description","","description of the file",30,null],[12,"word_rules","","the word rules",30,null],[12,"pos_rules","","the POS rules",30,null],[12,"math_rules","","the math rules",30,null],[12,"mtext_rules","","the mtext rules (math symbols)",30,null],[12,"sequence_rules","","the sequence rules",30,null],[12,"word_rule_names","","matches names of word rules to their offsets",30,null],[12,"pos_rule_names","","matches names of POS rules to their offsets",30,null],[12,"math_rule_names","","matches names of math rules to their offsets",30,null],[12,"mtext_rule_names","","matches names of mtext rules to their offsets",30,null],[12,"sequence_rule_names","","matches names of sequence rules to their offsets",30,null],[3,"PatternMarker","","The marker used for marking patterns. If a match was …",null,null],[12,"name","","name of the marker",31,null],[12,"tags","","tags of the marker",31,null],[3,"TextMarker","","A marked text range",null,null],[12,"range","","the marked range",32,null],[12,"marker","","the marker",32,null],[0,"stopwords","llamapun","A tiny stopwords library Stopwords are words frequent …",null,null],[5,"load","llamapun::stopwords","Load a set of stopwords Annoyingly, <code>HashSet</code>s are not …",null,[[],[["str",15],["hashset",3]]]],[0,"tokenizer","llamapun","Provides functionality for tokenizing sentences and words",null,null],[3,"Tokenizer","llamapun::tokenizer","Stores auxiliary resources required by the tokenizer so …",null,null],[12,"stopwords","","set of stopwords",33,null],[12,"abbreviations","","regular expression for abbreviations",33,null],[11,"sentences","","gets the sentences from a dnm",33,[[["dnm",3]],[["dnmrange",3],["vec",3]]]],[11,"words","","returns the words of a sentence using simple heuristics",33,[[["dnmrange",3]],[["vec",3],["dnmrange",3]]]],[11,"words_and_punct","","returns the words and punctuation of a sentence, using …",33,[[["dnmrange",3]],[["vec",3],["dnmrange",3]]]],[0,"extern_use","llamapun","Expose convenience calls to be used from non-Rust …",null,null],[5,"word_tokenize_for_vec2doc","llamapun::extern_use","Interface function for vec2doc-expected word tokenization …",null,[[]]],[14,"record_node_map","llamapun","A handy macro for idiomatic recording in the node_map",null,null],[11,"from","llamapun::util::data_helpers","",0,[[]]],[11,"into","","",0,[[]]],[11,"borrow","","",0,[[]]],[11,"borrow_mut","","",0,[[]]],[11,"try_from","","",0,[[],["result",4]]],[11,"try_into","","",0,[[],["result",4]]],[11,"type_id","","",0,[[],["typeid",3]]],[11,"init","","",0,[[],["usize",15]]],[11,"deref","","",0,[[["usize",15]]]],[11,"deref_mut","","",0,[[["usize",15]]]],[11,"drop","","",0,[[["usize",15]]]],[11,"from","llamapun::util::test","",34,[[]]],[11,"into","","",34,[[]]],[11,"borrow","","",34,[[]]],[11,"borrow_mut","","",34,[[]]],[11,"try_from","","",34,[[],["result",4]]],[11,"try_into","","",34,[[],["result",4]]],[11,"type_id","","",34,[[],["typeid",3]]],[11,"init","","",34,[[],["usize",15]]],[11,"deref","","",34,[[["usize",15]]]],[11,"deref_mut","","",34,[[["usize",15]]]],[11,"drop","","",34,[[["usize",15]]]],[11,"from","llamapun::ams","",1,[[]]],[11,"into","","",1,[[]]],[11,"to_owned","","",1,[[]]],[11,"clone_into","","",1,[[]]],[11,"to_string","","",1,[[],["string",3]]],[11,"borrow","","",1,[[]]],[11,"borrow_mut","","",1,[[]]],[11,"try_from","","",1,[[],["result",4]]],[11,"try_into","","",1,[[],["result",4]]],[11,"type_id","","",1,[[],["typeid",3]]],[11,"init","","",1,[[],["usize",15]]],[11,"deref","","",1,[[["usize",15]]]],[11,"deref_mut","","",1,[[["usize",15]]]],[11,"drop","","",1,[[["usize",15]]]],[11,"from","","",2,[[]]],[11,"into","","",2,[[]]],[11,"to_owned","","",2,[[]]],[11,"clone_into","","",2,[[]]],[11,"to_string","","",2,[[],["string",3]]],[11,"borrow","","",2,[[]]],[11,"borrow_mut","","",2,[[]]],[11,"try_from","","",2,[[],["result",4]]],[11,"try_into","","",2,[[],["result",4]]],[11,"type_id","","",2,[[],["typeid",3]]],[11,"init","","",2,[[],["usize",15]]],[11,"deref","","",2,[[["usize",15]]]],[11,"deref_mut","","",2,[[["usize",15]]]],[11,"drop","","",2,[[["usize",15]]]],[11,"from","llamapun::data","",3,[[]]],[11,"into","","",3,[[]]],[11,"borrow","","",3,[[]]],[11,"borrow_mut","","",3,[[]]],[11,"try_from","","",3,[[],["result",4]]],[11,"try_into","","",3,[[],["result",4]]],[11,"type_id","","",3,[[],["typeid",3]]],[11,"init","","",3,[[],["usize",15]]],[11,"deref","","",3,[[["usize",15]]]],[11,"deref_mut","","",3,[[["usize",15]]]],[11,"drop","","",3,[[["usize",15]]]],[11,"from","","",4,[[]]],[11,"into","","",4,[[]]],[11,"into_iter","","",4,[[]]],[11,"borrow","","",4,[[]]],[11,"borrow_mut","","",4,[[]]],[11,"try_from","","",4,[[],["result",4]]],[11,"try_into","","",4,[[],["result",4]]],[11,"type_id","","",4,[[],["typeid",3]]],[11,"init","","",4,[[],["usize",15]]],[11,"deref","","",4,[[["usize",15]]]],[11,"deref_mut","","",4,[[["usize",15]]]],[11,"drop","","",4,[[["usize",15]]]],[11,"from","","",5,[[]]],[11,"into","","",5,[[]]],[11,"borrow","","",5,[[]]],[11,"borrow_mut","","",5,[[]]],[11,"try_from","","",5,[[],["result",4]]],[11,"try_into","","",5,[[],["result",4]]],[11,"type_id","","",5,[[],["typeid",3]]],[11,"init","","",5,[[],["usize",15]]],[11,"deref","","",5,[[["usize",15]]]],[11,"deref_mut","","",5,[[["usize",15]]]],[11,"drop","","",5,[[["usize",15]]]],[11,"from","","",6,[[]]],[11,"into","","",6,[[]]],[11,"into_iter","","",6,[[]]],[11,"borrow","","",6,[[]]],[11,"borrow_mut","","",6,[[]]],[11,"try_from","","",6,[[],["result",4]]],[11,"try_into","","",6,[[],["result",4]]],[11,"type_id","","",6,[[],["typeid",3]]],[11,"init","","",6,[[],["usize",15]]],[11,"deref","","",6,[[["usize",15]]]],[11,"deref_mut","","",6,[[["usize",15]]]],[11,"drop","","",6,[[["usize",15]]]],[11,"from","","",7,[[]]],[11,"into","","",7,[[]]],[11,"borrow","","",7,[[]]],[11,"borrow_mut","","",7,[[]]],[11,"try_from","","",7,[[],["result",4]]],[11,"try_into","","",7,[[],["result",4]]],[11,"type_id","","",7,[[],["typeid",3]]],[11,"init","","",7,[[],["usize",15]]],[11,"deref","","",7,[[["usize",15]]]],[11,"deref_mut","","",7,[[["usize",15]]]],[11,"drop","","",7,[[["usize",15]]]],[11,"from","","",8,[[]]],[11,"into","","",8,[[]]],[11,"into_iter","","",8,[[]]],[11,"borrow","","",8,[[]]],[11,"borrow_mut","","",8,[[]]],[11,"try_from","","",8,[[],["result",4]]],[11,"try_into","","",8,[[],["result",4]]],[11,"type_id","","",8,[[],["typeid",3]]],[11,"init","","",8,[[],["usize",15]]],[11,"deref","","",8,[[["usize",15]]]],[11,"deref_mut","","",8,[[["usize",15]]]],[11,"drop","","",8,[[["usize",15]]]],[11,"from","","",9,[[]]],[11,"into","","",9,[[]]],[11,"borrow","","",9,[[]]],[11,"borrow_mut","","",9,[[]]],[11,"try_from","","",9,[[],["result",4]]],[11,"try_into","","",9,[[],["result",4]]],[11,"type_id","","",9,[[],["typeid",3]]],[11,"init","","",9,[[],["usize",15]]],[11,"deref","","",9,[[["usize",15]]]],[11,"deref_mut","","",9,[[["usize",15]]]],[11,"drop","","",9,[[["usize",15]]]],[11,"from","","",10,[[]]],[11,"into","","",10,[[]]],[11,"into_iter","","",10,[[]]],[11,"borrow","","",10,[[]]],[11,"borrow_mut","","",10,[[]]],[11,"try_from","","",10,[[],["result",4]]],[11,"try_into","","",10,[[],["result",4]]],[11,"type_id","","",10,[[],["typeid",3]]],[11,"init","","",10,[[],["usize",15]]],[11,"deref","","",10,[[["usize",15]]]],[11,"deref_mut","","",10,[[["usize",15]]]],[11,"drop","","",10,[[["usize",15]]]],[11,"from","","",11,[[]]],[11,"into","","",11,[[]]],[11,"into_iter","","",11,[[]]],[11,"borrow","","",11,[[]]],[11,"borrow_mut","","",11,[[]]],[11,"try_from","","",11,[[],["result",4]]],[11,"try_into","","",11,[[],["result",4]]],[11,"type_id","","",11,[[],["typeid",3]]],[11,"init","","",11,[[],["usize",15]]],[11,"deref","","",11,[[["usize",15]]]],[11,"deref_mut","","",11,[[["usize",15]]]],[11,"drop","","",11,[[["usize",15]]]],[11,"from","","",12,[[]]],[11,"into","","",12,[[]]],[11,"borrow","","",12,[[]]],[11,"borrow_mut","","",12,[[]]],[11,"try_from","","",12,[[],["result",4]]],[11,"try_into","","",12,[[],["result",4]]],[11,"type_id","","",12,[[],["typeid",3]]],[11,"init","","",12,[[],["usize",15]]],[11,"deref","","",12,[[["usize",15]]]],[11,"deref_mut","","",12,[[["usize",15]]]],[11,"drop","","",12,[[["usize",15]]]],[11,"from","llamapun::dnm","",14,[[]]],[11,"into","","",14,[[]]],[11,"borrow","","",14,[[]]],[11,"borrow_mut","","",14,[[]]],[11,"try_from","","",14,[[],["result",4]]],[11,"try_into","","",14,[[],["result",4]]],[11,"type_id","","",14,[[],["typeid",3]]],[11,"init","","",14,[[],["usize",15]]],[11,"deref","","",14,[[["usize",15]]]],[11,"deref_mut","","",14,[[["usize",15]]]],[11,"drop","","",14,[[["usize",15]]]],[11,"from","","",15,[[]]],[11,"into","","",15,[[]]],[11,"to_owned","","",15,[[]]],[11,"clone_into","","",15,[[]]],[11,"borrow","","",15,[[]]],[11,"borrow_mut","","",15,[[]]],[11,"try_from","","",15,[[],["result",4]]],[11,"try_into","","",15,[[],["result",4]]],[11,"type_id","","",15,[[],["typeid",3]]],[11,"init","","",15,[[],["usize",15]]],[11,"deref","","",15,[[["usize",15]]]],[11,"deref_mut","","",15,[[["usize",15]]]],[11,"drop","","",15,[[["usize",15]]]],[11,"from","","",13,[[]]],[11,"into","","",13,[[]]],[11,"to_owned","","",13,[[]]],[11,"clone_into","","",13,[[]]],[11,"borrow","","",13,[[]]],[11,"borrow_mut","","",13,[[]]],[11,"try_from","","",13,[[],["result",4]]],[11,"try_into","","",13,[[],["result",4]]],[11,"type_id","","",13,[[],["typeid",3]]],[11,"init","","",13,[[],["usize",15]]],[11,"deref","","",13,[[["usize",15]]]],[11,"deref_mut","","",13,[[["usize",15]]]],[11,"drop","","",13,[[["usize",15]]]],[11,"from","","",16,[[]]],[11,"into","","",16,[[]]],[11,"to_owned","","",16,[[]]],[11,"clone_into","","",16,[[]]],[11,"borrow","","",16,[[]]],[11,"borrow_mut","","",16,[[]]],[11,"try_from","","",16,[[],["result",4]]],[11,"try_into","","",16,[[],["result",4]]],[11,"type_id","","",16,[[],["typeid",3]]],[11,"init","","",16,[[],["usize",15]]],[11,"deref","","",16,[[["usize",15]]]],[11,"deref_mut","","",16,[[["usize",15]]]],[11,"drop","","",16,[[["usize",15]]]],[11,"from","","",17,[[]]],[11,"into","","",17,[[]]],[11,"borrow","","",17,[[]]],[11,"borrow_mut","","",17,[[]]],[11,"try_from","","",17,[[],["result",4]]],[11,"try_into","","",17,[[],["result",4]]],[11,"type_id","","",17,[[],["typeid",3]]],[11,"init","","",17,[[],["usize",15]]],[11,"deref","","",17,[[["usize",15]]]],[11,"deref_mut","","",17,[[["usize",15]]]],[11,"drop","","",17,[[["usize",15]]]],[11,"from","llamapun::ngrams","",18,[[]]],[11,"into","","",18,[[]]],[11,"borrow","","",18,[[]]],[11,"borrow_mut","","",18,[[]]],[11,"try_from","","",18,[[],["result",4]]],[11,"try_into","","",18,[[],["result",4]]],[11,"type_id","","",18,[[],["typeid",3]]],[11,"init","","",18,[[],["usize",15]]],[11,"deref","","",18,[[["usize",15]]]],[11,"deref_mut","","",18,[[["usize",15]]]],[11,"drop","","",18,[[["usize",15]]]],[11,"from","","",19,[[]]],[11,"into","","",19,[[]]],[11,"borrow","","",19,[[]]],[11,"borrow_mut","","",19,[[]]],[11,"try_from","","",19,[[],["result",4]]],[11,"try_into","","",19,[[],["result",4]]],[11,"type_id","","",19,[[],["typeid",3]]],[11,"init","","",19,[[],["usize",15]]],[11,"deref","","",19,[[["usize",15]]]],[11,"deref_mut","","",19,[[["usize",15]]]],[11,"drop","","",19,[[["usize",15]]]],[11,"from","llamapun::parallel_data::corpus","",20,[[]]],[11,"into","","",20,[[]]],[11,"borrow","","",20,[[]]],[11,"borrow_mut","","",20,[[]]],[11,"try_from","","",20,[[],["result",4]]],[11,"try_into","","",20,[[],["result",4]]],[11,"type_id","","",20,[[],["typeid",3]]],[11,"init","","",20,[[],["usize",15]]],[11,"deref","","",20,[[["usize",15]]]],[11,"deref_mut","","",20,[[["usize",15]]]],[11,"drop","","",20,[[["usize",15]]]],[11,"from","llamapun::parallel_data::document","",21,[[]]],[11,"into","","",21,[[]]],[11,"borrow","","",21,[[]]],[11,"borrow_mut","","",21,[[]]],[11,"try_from","","",21,[[],["result",4]]],[11,"try_into","","",21,[[],["result",4]]],[11,"type_id","","",21,[[],["typeid",3]]],[11,"init","","",21,[[],["usize",15]]],[11,"deref","","",21,[[["usize",15]]]],[11,"deref_mut","","",21,[[["usize",15]]]],[11,"drop","","",21,[[["usize",15]]]],[11,"from","llamapun::parallel_data","",22,[[]]],[11,"into","","",22,[[]]],[11,"borrow","","",22,[[]]],[11,"borrow_mut","","",22,[[]]],[11,"try_from","","",22,[[],["result",4]]],[11,"try_into","","",22,[[],["result",4]]],[11,"type_id","","",22,[[],["typeid",3]]],[11,"init","","",22,[[],["usize",15]]],[11,"deref","","",22,[[["usize",15]]]],[11,"deref_mut","","",22,[[["usize",15]]]],[11,"drop","","",22,[[["usize",15]]]],[11,"from","","",23,[[]]],[11,"into","","",23,[[]]],[11,"borrow","","",23,[[]]],[11,"borrow_mut","","",23,[[]]],[11,"try_from","","",23,[[],["result",4]]],[11,"try_into","","",23,[[],["result",4]]],[11,"type_id","","",23,[[],["typeid",3]]],[11,"init","","",23,[[],["usize",15]]],[11,"deref","","",23,[[["usize",15]]]],[11,"deref_mut","","",23,[[["usize",15]]]],[11,"drop","","",23,[[["usize",15]]]],[11,"from","","",24,[[]]],[11,"into","","",24,[[]]],[11,"into_iter","","",24,[[]]],[11,"borrow","","",24,[[]]],[11,"borrow_mut","","",24,[[]]],[11,"try_from","","",24,[[],["result",4]]],[11,"try_into","","",24,[[],["result",4]]],[11,"type_id","","",24,[[],["typeid",3]]],[11,"init","","",24,[[],["usize",15]]],[11,"deref","","",24,[[["usize",15]]]],[11,"deref_mut","","",24,[[["usize",15]]]],[11,"drop","","",24,[[["usize",15]]]],[11,"from","","",25,[[]]],[11,"into","","",25,[[]]],[11,"into_iter","","",25,[[]]],[11,"borrow","","",25,[[]]],[11,"borrow_mut","","",25,[[]]],[11,"try_from","","",25,[[],["result",4]]],[11,"try_into","","",25,[[],["result",4]]],[11,"type_id","","",25,[[],["typeid",3]]],[11,"init","","",25,[[],["usize",15]]],[11,"deref","","",25,[[["usize",15]]]],[11,"deref_mut","","",25,[[["usize",15]]]],[11,"drop","","",25,[[["usize",15]]]],[11,"from","llamapun::patterns","",27,[[]]],[11,"into","","",27,[[]]],[11,"to_owned","","",27,[[]]],[11,"clone_into","","",27,[[]]],[11,"borrow","","",27,[[]]],[11,"borrow_mut","","",27,[[]]],[11,"try_from","","",27,[[],["result",4]]],[11,"try_into","","",27,[[],["result",4]]],[11,"type_id","","",27,[[],["typeid",3]]],[11,"init","","",27,[[],["usize",15]]],[11,"deref","","",27,[[["usize",15]]]],[11,"deref_mut","","",27,[[["usize",15]]]],[11,"drop","","",27,[[["usize",15]]]],[11,"from","","",31,[[]]],[11,"into","","",31,[[]]],[11,"to_owned","","",31,[[]]],[11,"clone_into","","",31,[[]]],[11,"borrow","","",31,[[]]],[11,"borrow_mut","","",31,[[]]],[11,"try_from","","",31,[[],["result",4]]],[11,"try_into","","",31,[[],["result",4]]],[11,"type_id","","",31,[[],["typeid",3]]],[11,"init","","",31,[[],["usize",15]]],[11,"deref","","",31,[[["usize",15]]]],[11,"deref_mut","","",31,[[["usize",15]]]],[11,"drop","","",31,[[["usize",15]]]],[11,"from","","",29,[[]]],[11,"into","","",29,[[]]],[11,"to_owned","","",29,[[]]],[11,"clone_into","","",29,[[]]],[11,"borrow","","",29,[[]]],[11,"borrow_mut","","",29,[[]]],[11,"try_from","","",29,[[],["result",4]]],[11,"try_into","","",29,[[],["result",4]]],[11,"type_id","","",29,[[],["typeid",3]]],[11,"init","","",29,[[],["usize",15]]],[11,"deref","","",29,[[["usize",15]]]],[11,"deref_mut","","",29,[[["usize",15]]]],[11,"drop","","",29,[[["usize",15]]]],[11,"from","","",32,[[]]],[11,"into","","",32,[[]]],[11,"to_owned","","",32,[[]]],[11,"clone_into","","",32,[[]]],[11,"borrow","","",32,[[]]],[11,"borrow_mut","","",32,[[]]],[11,"try_from","","",32,[[],["result",4]]],[11,"try_into","","",32,[[],["result",4]]],[11,"type_id","","",32,[[],["typeid",3]]],[11,"init","","",32,[[],["usize",15]]],[11,"deref","","",32,[[["usize",15]]]],[11,"deref_mut","","",32,[[["usize",15]]]],[11,"drop","","",32,[[["usize",15]]]],[11,"from","","",28,[[]]],[11,"into","","",28,[[]]],[11,"to_owned","","",28,[[]]],[11,"clone_into","","",28,[[]]],[11,"borrow","","",28,[[]]],[11,"borrow_mut","","",28,[[]]],[11,"try_from","","",28,[[],["result",4]]],[11,"try_into","","",28,[[],["result",4]]],[11,"type_id","","",28,[[],["typeid",3]]],[11,"init","","",28,[[],["usize",15]]],[11,"deref","","",28,[[["usize",15]]]],[11,"deref_mut","","",28,[[["usize",15]]]],[11,"drop","","",28,[[["usize",15]]]],[11,"from","","",30,[[]]],[11,"into","","",30,[[]]],[11,"borrow","","",30,[[]]],[11,"borrow_mut","","",30,[[]]],[11,"try_from","","",30,[[],["result",4]]],[11,"try_into","","",30,[[],["result",4]]],[11,"type_id","","",30,[[],["typeid",3]]],[11,"init","","",30,[[],["usize",15]]],[11,"deref","","",30,[[["usize",15]]]],[11,"deref_mut","","",30,[[["usize",15]]]],[11,"drop","","",30,[[["usize",15]]]],[11,"from","llamapun::tokenizer","",33,[[]]],[11,"into","","",33,[[]]],[11,"borrow","","",33,[[]]],[11,"borrow_mut","","",33,[[]]],[11,"try_from","","",33,[[],["result",4]]],[11,"try_into","","",33,[[],["result",4]]],[11,"type_id","","",33,[[],["typeid",3]]],[11,"init","","",33,[[],["usize",15]]],[11,"deref","","",33,[[["usize",15]]]],[11,"deref_mut","","",33,[[["usize",15]]]],[11,"drop","","",33,[[["usize",15]]]],[11,"get_document","llamapun::parallel_data","",22,[[],["document",3]]],[11,"to_sentences","","",22,[[],[["vec",3],["dnmrange",3]]]],[11,"from","llamapun::ams","",1,[[["str",15]],["structuralenv",4]]],[11,"next","llamapun::data","",4,[[],[["option",4],["document",3]]]],[11,"next","","",6,[[],[["paragraph",3],["option",4]]]],[11,"next","","",8,[[],[["sentence",3],["option",4]]]],[11,"next","","",10,[[],[["option",4],["word",3]]]],[11,"next","","",11,[[],[["option",4],["word",3]]]],[11,"next","llamapun::parallel_data","",24,[[],[["option",4],["itemdnm",3]]]],[11,"next","","",25,[[],[["itemdnmrange",3],["option",4]]]],[11,"clone","llamapun::ams","",1,[[],["structuralenv",4]]],[11,"clone","","",2,[[],["amsenv",4]]],[11,"clone","llamapun::dnm","",15,[[],["specialtagsoption",4]]],[11,"clone","","",13,[[],["dnmparameters",3]]],[11,"clone","","",16,[[],["dnmrange",3]]],[11,"clone","llamapun::patterns","",27,[[],["match",3]]],[11,"clone","","",31,[[],["patternmarker",3]]],[11,"clone","","",29,[[],["mathmarker",3]]],[11,"clone","","",32,[[],["textmarker",3]]],[11,"clone","","",28,[[],["markerenum",4]]],[11,"default","llamapun::util::data_helpers","",0,[[]]],[11,"default","llamapun::data","",3,[[],["corpus",3]]],[11,"default","llamapun::dnm","",14,[[],["runtimeparsedata",3]]],[11,"default","","Don\'t do anything fancy and specific by default",13,[[],["dnmparameters",3]]],[11,"default","","",17,[[],["dnm",3]]],[11,"default","llamapun::ngrams","",18,[[],["dictionary",3]]],[11,"default","","",19,[[],["ngrams",3]]],[11,"default","llamapun::parallel_data::corpus","",20,[[],["corpus",3]]],[11,"default","llamapun::tokenizer","",33,[[],["tokenizer",3]]],[11,"eq","llamapun::ams","",1,[[["structuralenv",4]],["bool",15]]],[11,"eq","","",2,[[["amsenv",4]],["bool",15]]],[11,"deref","llamapun::util::test","",34,[[],["vec",3]]],[11,"fmt","llamapun::ams","",1,[[["formatter",3]],["result",6]]],[11,"fmt","","",2,[[["formatter",3]],["result",6]]],[11,"fmt","llamapun::dnm","",14,[[["formatter",3]],["result",6]]],[11,"fmt","","",15,[[["formatter",3]],["result",6]]],[11,"fmt","","",13,[[["formatter",3]],["result",6]]],[11,"fmt","","",16,[[["formatter",3]],["result",6]]],[11,"fmt","","",17,[[["formatter",3]],["result",6]]],[11,"fmt","llamapun::ams","",1,[[["formatter",3]],["result",6]]],[11,"fmt","","",2,[[["formatter",3]],["result",6]]],[11,"initialize","llamapun::util::test","",34,[[]]],[11,"to_c14n_basic","llamapun::dnm","Our linguistic canonical form will only include 1) node …",17,[[],["string",3]]],[11,"node_c14n_basic","","Canonicalize a single node of choice",17,[[["ronode",3]],["string",3]]],[11,"to_hash_basic","","Obtain an MD5 hash from the canonical string of the …",17,[[],["string",3]]],[11,"node_hash_basic","","Obtain an MD5 hash from the canonical string of a Node",17,[[["ronode",3]],["string",3]]],[11,"llamapun_normalization","","Normalize in a reasonable way for our math documents",13,[[],["dnmparameters",3]]],[11,"check","","Prints warnings, if the parameter settings don\'t make …",13,[[]]],[11,"get_plaintext","","Get the plaintext substring corresponding to the range",16,[[],["str",15]]],[11,"get_plaintext_truncated","","Get the plaintext without trailing white spaces",16,[[],["str",15]]],[11,"get_node","","Get the first corresponding DOM node for this range",16,[[],["ronode",3]]],[11,"trim","","Returns a <code>DNMRange</code> with the leading and trailing …",16,[[],["dnmrange",3]]],[11,"get_subrange","","returns a subrange, with offsets relative to the …",16,[[["usize",15]],["dnmrange",3]]],[11,"get_subrange_from_byte_offsets","","returns a subrange from a pair of byte offsets (not …",16,[[["usize",15]],["dnmrange",3]]],[11,"is_empty","","checks whether the range is empty",16,[[],["bool",15]]],[11,"serialize","","serializes a DNMRange into an XPointer",16,[[],["string",3]]],[11,"create_arange","","creates an arange from to xpointers",16,[[["str",15]],["string",3]]],[11,"serialize_offset","","Serializes a node and an offset into an xpointer is_end …",16,[[["bool",15],["ronode",3],["i32",15]],["string",3]]],[11,"serialize_node","","serializes a node into an xpath expression",16,[[["bool",15],["ronode",3]],["string",3]]],[11,"deserialize","","deserializes an xpointer into a <code>DNMRange</code>. Note that only …",16,[[["dnm",3],["context",3],["str",15]],["dnmrange",3]]],[11,"get_marker_list","llamapun::patterns","returns a list of all markers",27,[[],[["markerenum",4],["vec",3]]]],[11,"load","","loads a pattern file",30,[[["str",15]],[["string",3],["result",4],["patternfile",3]]]]],"p":[[3,"LexicalOptions"],[4,"StructuralEnv"],[4,"AmsEnv"],[3,"Corpus"],[3,"DocumentIterator"],[3,"Document"],[3,"ParagraphIterator"],[3,"Paragraph"],[3,"SentenceIterator"],[3,"Sentence"],[3,"SimpleWordIterator"],[3,"SennaWordIterator"],[3,"Word"],[3,"DNMParameters"],[3,"RuntimeParseData"],[4,"SpecialTagsOption"],[3,"DNMRange"],[3,"DNM"],[3,"Dictionary"],[3,"Ngrams"],[3,"Corpus"],[3,"Document"],[3,"ItemDNM"],[3,"ItemDNMRange"],[3,"RoNodeIterator"],[3,"DNMRangeIterator"],[8,"XPathFilteredIterator"],[3,"Match"],[4,"MarkerEnum"],[3,"MathMarker"],[3,"PatternFile"],[3,"PatternMarker"],[3,"TextMarker"],[3,"Tokenizer"],[3,"RESOURCE_DOCUMENTS"]]}\
}');
addSearchOptions(searchIndex);initSearch(searchIndex);